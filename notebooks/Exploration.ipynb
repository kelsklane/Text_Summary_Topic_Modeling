{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>claps</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Justin Lee</td>\n",
       "      <td>8.3K</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/swlh/chatbots-were-the-next...</td>\n",
       "      <td>Chatbots were the next big thing: what happene...</td>\n",
       "      <td>Oh, how the headlines blared:\\nChatbots were T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Conor Dewey</td>\n",
       "      <td>1.4K</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/python-for-data...</td>\n",
       "      <td>Python for Data Science: 8 Concepts You May Ha...</td>\n",
       "      <td>If you’ve ever found yourself looking up the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>William Koehrsen</td>\n",
       "      <td>2.8K</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/automated-featu...</td>\n",
       "      <td>Automated Feature Engineering in Python – Towa...</td>\n",
       "      <td>Machine learning is increasingly moving from h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gant Laborde</td>\n",
       "      <td>1.3K</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.freecodecamp.org/machine-learni...</td>\n",
       "      <td>Machine Learning: how to go from Zero to Hero ...</td>\n",
       "      <td>If your understanding of A.I. and Machine Lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emmanuel Ameisen</td>\n",
       "      <td>935</td>\n",
       "      <td>11</td>\n",
       "      <td>https://blog.insightdatascience.com/reinforcem...</td>\n",
       "      <td>Reinforcement Learning from scratch – Insight ...</td>\n",
       "      <td>Want to learn about applied Artificial Intelli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author claps  reading_time  \\\n",
       "0        Justin Lee  8.3K            11   \n",
       "1       Conor Dewey  1.4K             7   \n",
       "2  William Koehrsen  2.8K            11   \n",
       "3      Gant Laborde  1.3K             7   \n",
       "4  Emmanuel Ameisen   935            11   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://medium.com/swlh/chatbots-were-the-next...   \n",
       "1  https://towardsdatascience.com/python-for-data...   \n",
       "2  https://towardsdatascience.com/automated-featu...   \n",
       "3  https://medium.freecodecamp.org/machine-learni...   \n",
       "4  https://blog.insightdatascience.com/reinforcem...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Chatbots were the next big thing: what happene...   \n",
       "1  Python for Data Science: 8 Concepts You May Ha...   \n",
       "2  Automated Feature Engineering in Python – Towa...   \n",
       "3  Machine Learning: how to go from Zero to Hero ...   \n",
       "4  Reinforcement Learning from scratch – Insight ...   \n",
       "\n",
       "                                                text  \n",
       "0  Oh, how the headlines blared:\\nChatbots were T...  \n",
       "1  If you’ve ever found yourself looking up the s...  \n",
       "2  Machine learning is increasingly moving from h...  \n",
       "3  If your understanding of A.I. and Machine Lear...  \n",
       "4  Want to learn about applied Artificial Intelli...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/articles.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn claps from str into int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_claps(num):\n",
    "    if num[-1] == 'K':\n",
    "        num = num[:-1]\n",
    "        num += '00'\n",
    "        num = num.replace('.', '') \n",
    "    return num\n",
    "df.claps = df.claps.apply(clean_up_claps)\n",
    "df.claps = df.claps.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claps</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8300</td>\n",
       "      <td>11</td>\n",
       "      <td>Chatbots were the next big thing: what happene...</td>\n",
       "      <td>Oh, how the headlines blared:\\nChatbots were T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1400</td>\n",
       "      <td>7</td>\n",
       "      <td>Python for Data Science: 8 Concepts You May Ha...</td>\n",
       "      <td>If you’ve ever found yourself looking up the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2800</td>\n",
       "      <td>11</td>\n",
       "      <td>Automated Feature Engineering in Python – Towa...</td>\n",
       "      <td>Machine learning is increasingly moving from h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1300</td>\n",
       "      <td>7</td>\n",
       "      <td>Machine Learning: how to go from Zero to Hero ...</td>\n",
       "      <td>If your understanding of A.I. and Machine Lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>935</td>\n",
       "      <td>11</td>\n",
       "      <td>Reinforcement Learning from scratch – Insight ...</td>\n",
       "      <td>Want to learn about applied Artificial Intelli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   claps  reading_time                                              title  \\\n",
       "0   8300            11  Chatbots were the next big thing: what happene...   \n",
       "1   1400             7  Python for Data Science: 8 Concepts You May Ha...   \n",
       "2   2800            11  Automated Feature Engineering in Python – Towa...   \n",
       "3   1300             7  Machine Learning: how to go from Zero to Hero ...   \n",
       "4    935            11  Reinforcement Learning from scratch – Insight ...   \n",
       "\n",
       "                                                text  \n",
       "0  Oh, how the headlines blared:\\nChatbots were T...  \n",
       "1  If you’ve ever found yourself looking up the s...  \n",
       "2  Machine learning is increasingly moving from h...  \n",
       "3  If your understanding of A.I. and Machine Lear...  \n",
       "4  Want to learn about applied Artificial Intelli...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get rid of link column\n",
    "df = df.drop(labels = ['link', 'author'], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import re\n",
    "\n",
    "punct = list(string.punctuation)\n",
    "sw = stopwords.words('english')\n",
    "\n",
    "def pos_replace(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def bare_text(text):\n",
    "    text = text.replace('\\n','')\n",
    "    text = text.lower()\n",
    "    #Adds spaces where they are missing after punctuation\n",
    "    text = re.sub(r'(?<=[.,\\?!])(?=[^\\s])', r' ', text)\n",
    "    #Tokenize text\n",
    "    text_token = word_tokenize(text)\n",
    "    #Get rid of stopwords\n",
    "    text_token = [w for w in text_token if w.lower() not in sw]\n",
    "    #Lemmatize text\n",
    "    text_token = pos_tag(text_token)\n",
    "    text_token = [(w[0], pos_replace(w[1])) for w in text_token]\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    text_token = [lemmatizer.lemmatize(word[0], word[1]) for word in text_token]\n",
    "    #Get rid of punctuation\n",
    "    text_token = [w for w in text_token if w not in punct]\n",
    "    #Special punctuation marks not included in original list\n",
    "    text_token = [w for w in text_token if w not in [\"’\", \"-\", \"‘\"]]\n",
    "    text = TreebankWordDetokenizer().detokenize(text_token)\n",
    "    return text\n",
    "\n",
    "def clean_sentences(text):\n",
    "    text = text.replace('\\n','')\n",
    "    #Get rid of links\n",
    "    text = re.sub(r'www\\.[a-z]?\\.?(com)+|[a-z]+\\.(com)', '', text)\n",
    "    #Add space after punctuation if its not there\n",
    "    text = re.sub(r'(?<=[.,\\?!:])(?=[^\\s])', r' ', text)\n",
    "    text = text.lower()\n",
    "    #Get rid of punctuation\n",
    "    text.replace(\"[^a-zA-Z]\", \" \").split(\" \")\n",
    "    sent = sent_tokenize(text)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_sim(sent1, sent2, stopwords = None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    " \n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    " \n",
    "    all_words = list(set(sent1 + sent2))\n",
    " \n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    " \n",
    "    # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector1[all_words.index(w)] += 1\n",
    " \n",
    "    # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector2[all_words.index(w)] += 1\n",
    " \n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_matrix(sent, stop_words = sw):\n",
    "    # Create an empty similarity matrix\n",
    "    similarity_matrix = np.zeros((len(sent), len(sent)))\n",
    " \n",
    "    for ind1 in range(len(sent)):\n",
    "        for ind2 in range(len(sent)):\n",
    "            if ind1 == ind2:\n",
    "                continue \n",
    "            similarity_matrix[ind1][ind2] = sent_sim(sent[ind1], sent[ind2], stop_words)\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize Text By Hand - Extractive Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(article, top_n = 3):\n",
    "    summarize_text = []\n",
    "    sentences =  clean_sentences(article)\n",
    "    #Find similar sentences\n",
    "    sentence_sim_martix = sim_matrix(sentences)\n",
    "    sentence_sim_graph = nx.from_numpy_array(sentence_sim_martix)\n",
    "    scores = nx.pagerank(sentence_sim_graph)\n",
    "    #Rank similarity and find summary sentences\n",
    "    ranked_sentence = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse = True)    \n",
    "    for i in range(top_n):\n",
    "        summarize_text.append(ranked_sentence[i][1])\n",
    "    summary = \" \".join(summarize_text)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Built in Genism Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization.summarizer import summarize\n",
    "\n",
    "def generate_summary_genism(article, word_count = 250):\n",
    "    sentences = clean_sentences(article)\n",
    "    text = \" \".join(sentences)\n",
    "    summary = summarize(text, word_count = word_count)\n",
    "    summary = summary.replace('\\n',' ')\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in the interest of solidifying my understanding of these concepts once and for all and saving you guys a couple of stackoverflow searches, here’s the stuff that i’m always forgetting when working with python, numpy, and pandas. writing out a for loop every time you need to define some sort of list is tedious, luckily python has a built-in way to address this problem in just one line of code. for creating quick and easy numpy arrays, look no further than the arange and linspace functions. each one has their specific purpose, but the appeal here (instead of using range), is that they output numpy arrays, which are typically easier to work with for data science. so given a starting and stopping point, as well as a number of values, linspace will evenly space them out for you in a numpy array. let’s use the example of dropping a column for now: i don’t know how many times i wrote this line of code before i actually knew why i was declaring axis what i was. if you think about how this is indexed in python, rows are at 0 and columns are at 1, much like how we declare our axis value. think of apply as a map function, but made for pandas dataframes or more specifically, for series. you might imagine how useful this can be, especially for formatting and manipulating values across a whole dataframe column, without having to loop at all.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df.text[1]\n",
    "generate_summary_genism(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
